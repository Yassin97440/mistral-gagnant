{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistralai import Mistral\n",
    "import requests\n",
    "import numpy as np\n",
    "import faiss\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "api_key= getpass(\"Type your API Key\")\n",
    "client = Mistral(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mise en place de l'API notion en cours test poussÃ©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_context=\"\"\" \n",
    "{\n",
    "  \"name\": \"Yassin Abdulla\",\n",
    "  \"shortDesciption\": \"DÃ©veloppeur Full Stack\",\n",
    "  \"longDescription1\": \" Salut, moi c'est Yassin, j'ai 24 ans et je suis un dÃ©veloppeur sympa ğŸ˜„. J'ai eu la chance de grandir dans l'ocÃ©an indien, majoritairement Ã  l'Ã®le de la rÃ©union. Avant de venir sur le continent pour continuer mes Ã©tudes post bac et pour dÃ©couvrir le monde.\",\n",
    "  \"longDescription2\": \"Cela fait maintenant 4 ans que je suis dÃ©veloppeur dans le monde du travail. Dont une annÃ©e en alternance. Avant cela, j'ai suivi un cursus orientÃ© Ã©lÃ©ctronique et IoT. J'ai pu y faire beaucoup d'Ã©lÃ©ctronique (et beaucoup d'Ã©quation du coup mdr), et Ã©galement du dÃ©veloppemnt en C++ avec arduino principalement. Mais aussi quelques notion en IHM (interface homme machine) dont des principalement des pages HTML, CSS, et JS. A la fin de mon BTS, j'avais un gros manque de connaissances et de compÃ©tences en ce qui concerne le dÃ©veloppement d'IHM. J'ai voulu dÃ©velopper mes compÃ©tences en dÃ©veloppement d'intÃ©rface graphique et web afin d'avoir un \\\"spectre\\\" de compÃ©tences plus large. Ce qui dans l'idÃ©e m'aurait permis d'avoir les compÃ©tences nÃ©cessaires pour concevoir et dÃ©velopper un projet de A Ã  Z. Qu'il soit purement logiciel ou bien en intÃ©grant des systÃ¨mes embarquÃ©s.\",\n",
    "  \"longDescription3\": \"Mais j'avoue que j'ai beaucoup trop kiffÃ© le dÃ©veloppement logiciel et web, et j'ai du coup mis de cÃ´tÃ© l'Ã©lÃ©ctronique ces 3 derniÃ¨res annÃ©es. C'est que en dÃ©vouvrant le monde du dÃ©veloppement logiciel et web, je me suis rapidement rendu compte de l'immensitÃ© technologique de ce monde, et Ã©galement cette diversitÃ© technique. Ce qui a beacoup attirÃ© mon attention. Plus que l'Ã©lÃ©ctronique sur le moment. Et pendant ces 4 derniÃ¨res annÃ©es j'ai du coup pu dÃ©couvrir et approfondir des notions en dÃ©veloppement d'application. De la conception et la mise en place d'une base de donnÃ©es, au dÃ©veloppement d'interfaces graphiques, et Ã©normÃ©ment de dÃ©veloppement du back-end pour la logique mÃ©tier (logique mÃ©tier assez complexe sur certains sujets Ã  ma premiÃ¨re expÃ©rience.\",\n",
    "  \"longDescription4\": \"Pendant ma premiÃ¨re annÃ©e en alternance je me suis rendu compte que les compÃ©tences techniques n'Ã©taient que la moitiÃ© des compÃ©tences nÃ©cessaires pour Ãªtre un bon dÃ©veloppeur. J'ai au fur et Ã  mesure pu dÃ©couvrir ce qu'est l'analyse du besoin client et son importance. J'ai pu monter Ã©normÃ©ment monter en compÃ©tences en JAV (spring et eclipse RCP). L'annÃ©e d'aprÃ¨s mon alternance, j'a eu la chance de commencer Ã  avoir des rÃ©sponsabilitÃ©s en gestion de projet et lead technique (java) de gestion d'Ã©quipe. \",\n",
    "  \"skills\": {\n",
    "    \"otherSkills\": [\n",
    "      \"Gestion de projet\",\n",
    "      \"Lead Dev Java \",\n",
    "      \"Gestion d'Ã©quipe\",\n",
    "      \"Analyse du besoin client\",\n",
    "      \"DÃ©veloppement d'interfaces graphiques\",\n",
    "      \"DÃ©veloppement back-end\",\n",
    "      \"Conception et mise en place de base de donnÃ©es\",\n",
    "      \"Communication avec les clients\",\n",
    "      \"Communication avec les Ã©quipes\"\n",
    "    ],\n",
    "    \"technos\": {\n",
    "      \"frontend\": [\n",
    "        \"Nuxt.js\",\n",
    "        \"RCP/SWT (java)\",\n",
    "        \"Tailwind CSS\",\n",
    "        \"Vuetify\",\n",
    "        \"PrimeVue\"\n",
    "      ],\n",
    "      \"backend\": [\n",
    "        \"Spring Boot\",\n",
    "        \"Java\",\n",
    "        \"Python\",\n",
    "        \"JavaScript\",\n",
    "        \"Node.js\",\n",
    "        \"Express\",\n",
    "        \"MySQL\"\n",
    "      ],\n",
    "      \"other\": [\n",
    "        \"Docker\",\n",
    "        \"TensorFlow\",\n",
    "        \"Numpy\"\n",
    "      ]\n",
    "    }\n",
    "  },\n",
    "  \"tools\": [\n",
    "    \"eclipse\",\n",
    "    \"Intellij IDEA\",\n",
    "    \"VSCode\",\n",
    "    \"Postman\",\n",
    "    \"Git\",\n",
    "    \"GitHub\",\n",
    "    \"GitLab\",\n",
    "    \"Jira\",\n",
    "    \"Confluence\",\n",
    "    \"Notion\",\n",
    "    \"Google Colab\",\n",
    "    \"Jupyter Notebook\",\n",
    "    \"WSL\"\n",
    "  ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3584"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = my_context\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_size = 2048\n",
    "chunks = [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yassin/miniconda3/envs/rag-env/lib/python3.10/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "# Initialiser le modÃ¨le\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_embedding(input):\n",
    "    return model.encode(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embeddings = np.array([get_text_embedding(chunk) for chunk in chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = text_embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(d)\n",
    "index.add(text_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#le prompt passe aussi par l'embedding, avec le meme model (important)\n",
    "question = \"Qu'Ã  fais Yassin aprÃ¨s son BAC?\"\n",
    "question_embeddings = np.array([get_text_embedding(question)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypothetical Document Embeddings (HyDE)\n",
    "dans certains cas, le prompt utilisateur peut ne pas etre la requete la plus pertinente pour identifier le contexte pertinent. Il est donc intÃ©rÃ©ssant de gÃ©nÃ©rer un document hypothÃ©tique qui serait plus perttinent pour identifier le contexte pertinant Ã  la question de l'utilisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param 1: question embedding, param 2: nombres de vecteur similaires Ã  rÃ©cupÃ©rer\n",
    "D, I = index.search(question_embeddings, k=2) # distance, index\n",
    "retrieved_chunk = [chunks[i] for i in I.tolist()[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ã  noter qu'il existe pleins d'autres stragÃ©tegie de recherces. search en tant une utilisation simple pour un cas simple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Context information is below.\n",
    "---------------------\n",
    "{retrieved_chunk}\n",
    "---------------------\n",
    "Given the context information and not prior knowledge, answer the query.\n",
    "Query: {question}\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mistral(user_message, model=\"mistral-large-latest\"):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\", \"content\": user_message\n",
    "        }\n",
    "    ]\n",
    "    chat_response = client.chat.complete(\n",
    "        model=model,\n",
    "        messages=messages\n",
    "    )\n",
    "    return (chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"AprÃ¨s son BAC, Yassin a suivi un cursus orientÃ© Ã©lectronique et IoT. Il y a fait beaucoup d'Ã©lectronique et de dÃ©veloppement en C++ avec Arduino, ainsi que quelques notions en IHM (interface homme-machine) avec des pages HTML, CSS, et JS.\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_mistral(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install notion-client\n",
    "import os\n",
    "from notion_client import Client\n",
    "\n",
    "notion = Client(auth=os.environ[\"NOTION_TOKEN\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Essaie avec langChain\n",
    "maintenant avoir compris les diffÃ©rentes Ã©tapes pour mettre en place un RAG, il est temps de passer sur un framework solide pour optimiser tout ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_mistralai.chat_models import ChatMistralAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "# Remplacement des embeddings Mistral par SentenceTransformer\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# loader = TextLoader(\"data.json\")\n",
    "# docs = loader.load()\n",
    "\n",
    "#autre facon de faire en rÃ©cupÃ©rrant ma variable my context\n",
    "doc = Document(page_content=my_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split text into chunks \n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    ")\n",
    "documents = text_splitter.split_documents([doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_104022/211966054.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "# DÃ©finir le modÃ¨le d'embedding avec SentenceTransformer via HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"all-MiniLM-L6-v2\",  # Vous utilisez dÃ©jÃ  ce modÃ¨le\n",
    "    model_kwargs={'device': 'cuda'},  # Vous pouvez spÃ©cifier 'cuda' si vous avez un GPU\n",
    "    encode_kwargs={'normalize_embeddings': True}  # RecommandÃ© pour la recherche de similaritÃ©\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the vector store \n",
    "vector = FAISS.from_documents(documents, embeddings)\n",
    "# Define a retriever interface\n",
    "retriever = vector.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "api_key= getpass(\"Type your API Key\")\n",
    "# Define LLM\n",
    "model = ChatMistralAI(mistral_api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prompt template\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yassin a une bonne maÃ®trise des technologies Java, notamment Spring Boot et Eclipse RCP/SWT pour le dÃ©veloppement back-end et les interfaces graphiques. Il maÃ®trise Ã©galement d'autres technologies pour le dÃ©veloppement back-end telles que Python, JavaScript, Node.js, Express, et MySQL. Pour le dÃ©veloppement front-end, il utilise Nuxt.js, Tailwind CSS, Vuetify, et PrimeVue. Il a Ã©galement des compÃ©tences dans l'utilisation d'outils tels que Docker, TensorFlow, Numpy, Git, Jira, Confluence, et Notion, entre autres. Globalement, il a une bonne maÃ®trise des technologies de dÃ©veloppement web et back-end.\n"
     ]
    }
   ],
   "source": [
    "# Create a retrieval chain to answer questions\n",
    "document_chain = create_stuff_documents_chain(model, prompt)\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "response = retrieval_chain.invoke({\"input\": \"En francais stp! Quelles technologies maitrise le plus Yassin? \"})\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
