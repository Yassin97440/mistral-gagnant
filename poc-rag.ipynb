{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistralai import Mistral\n",
    "import requests\n",
    "import numpy as np\n",
    "import faiss\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "api_key= getpass(\"Type your API Key\")\n",
    "client = Mistral(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mise en place de l'API notion en cours test pouss√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_context=\"\"\" \n",
    "{\n",
    "  \"name\": \"Yassin Abdulla\",\n",
    "  \"shortDesciption\": \"D√©veloppeur Full Stack\",\n",
    "  \"longDescription1\": \" Salut, moi c'est Yassin, j'ai 24 ans et je suis un d√©veloppeur sympa üòÑ. J'ai eu la chance de grandir dans l'oc√©an indien, majoritairement √† l'√Æle de la r√©union. Avant de venir sur le continent pour continuer mes √©tudes post bac et pour d√©couvrir le monde.\",\n",
    "  \"longDescription2\": \"Cela fait maintenant 4 ans que je suis d√©veloppeur dans le monde du travail. Dont une ann√©e en alternance. Avant cela, j'ai suivi un cursus orient√© √©l√©ctronique et IoT. J'ai pu y faire beaucoup d'√©l√©ctronique (et beaucoup d'√©quation du coup mdr), et √©galement du d√©veloppemnt en C++ avec arduino principalement. Mais aussi quelques notion en IHM (interface homme machine) dont des principalement des pages HTML, CSS, et JS. A la fin de mon BTS, j'avais un gros manque de connaissances et de comp√©tences en ce qui concerne le d√©veloppement d'IHM. J'ai voulu d√©velopper mes comp√©tences en d√©veloppement d'int√©rface graphique et web afin d'avoir un \\\"spectre\\\" de comp√©tences plus large. Ce qui dans l'id√©e m'aurait permis d'avoir les comp√©tences n√©cessaires pour concevoir et d√©velopper un projet de A √† Z. Qu'il soit purement logiciel ou bien en int√©grant des syst√®mes embarqu√©s.\",\n",
    "  \"longDescription3\": \"Mais j'avoue que j'ai beaucoup trop kiff√© le d√©veloppement logiciel et web, et j'ai du coup mis de c√¥t√© l'√©l√©ctronique ces 3 derni√®res ann√©es. C'est que en d√©vouvrant le monde du d√©veloppement logiciel et web, je me suis rapidement rendu compte de l'immensit√© technologique de ce monde, et √©galement cette diversit√© technique. Ce qui a beacoup attir√© mon attention. Plus que l'√©l√©ctronique sur le moment. Et pendant ces 4 derni√®res ann√©es j'ai du coup pu d√©couvrir et approfondir des notions en d√©veloppement d'application. De la conception et la mise en place d'une base de donn√©es, au d√©veloppement d'interfaces graphiques, et √©norm√©ment de d√©veloppement du back-end pour la logique m√©tier (logique m√©tier assez complexe sur certains sujets √† ma premi√®re exp√©rience.\",\n",
    "  \"longDescription4\": \"Pendant ma premi√®re ann√©e en alternance je me suis rendu compte que les comp√©tences techniques n'√©taient que la moiti√© des comp√©tences n√©cessaires pour √™tre un bon d√©veloppeur. J'ai au fur et √† mesure pu d√©couvrir ce qu'est l'analyse du besoin client et son importance. J'ai pu monter √©norm√©ment monter en comp√©tences en JAV (spring et eclipse RCP). L'ann√©e d'apr√®s mon alternance, j'a eu la chance de commencer √† avoir des r√©sponsabilit√©s en gestion de projet et lead technique (java) de gestion d'√©quipe. \",\n",
    "  \"skills\": {\n",
    "    \"otherSkills\": [\n",
    "      \"Gestion de projet\",\n",
    "      \"Lead Dev Java \",\n",
    "      \"Gestion d'√©quipe\",\n",
    "      \"Analyse du besoin client\",\n",
    "      \"D√©veloppement d'interfaces graphiques\",\n",
    "      \"D√©veloppement back-end\",\n",
    "      \"Conception et mise en place de base de donn√©es\",\n",
    "      \"Communication avec les clients\",\n",
    "      \"Communication avec les √©quipes\"\n",
    "    ],\n",
    "    \"technos\": {\n",
    "      \"frontend\": [\n",
    "        \"Nuxt.js\",\n",
    "        \"RCP/SWT (java)\",\n",
    "        \"Tailwind CSS\",\n",
    "        \"Vuetify\",\n",
    "        \"PrimeVue\"\n",
    "      ],\n",
    "      \"backend\": [\n",
    "        \"Spring Boot\",\n",
    "        \"Java\",\n",
    "        \"Python\",\n",
    "        \"JavaScript\",\n",
    "        \"Node.js\",\n",
    "        \"Express\",\n",
    "        \"MySQL\"\n",
    "      ],\n",
    "      \"other\": [\n",
    "        \"Docker\",\n",
    "        \"TensorFlow\",\n",
    "        \"Numpy\"\n",
    "      ]\n",
    "    }\n",
    "  },\n",
    "  \"tools\": [\n",
    "    \"eclipse\",\n",
    "    \"Intellij IDEA\",\n",
    "    \"VSCode\",\n",
    "    \"Postman\",\n",
    "    \"Git\",\n",
    "    \"GitHub\",\n",
    "    \"GitLab\",\n",
    "    \"Jira\",\n",
    "    \"Confluence\",\n",
    "    \"Notion\",\n",
    "    \"Google Colab\",\n",
    "    \"Jupyter Notebook\",\n",
    "    \"WSL\"\n",
    "  ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3584"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = my_context\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_size = 2048\n",
    "chunks = [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yassin/miniconda3/envs/rag-env/lib/python3.10/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "# Initialiser le mod√®le\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_embedding(input):\n",
    "    return model.encode(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embeddings = np.array([get_text_embedding(chunk) for chunk in chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = text_embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(d)\n",
    "index.add(text_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#le prompt passe aussi par l'embedding, avec le meme model (important)\n",
    "question = \"Qu'√† fais Yassin apr√®s son BAC?\"\n",
    "question_embeddings = np.array([get_text_embedding(question)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypothetical Document Embeddings (HyDE)\n",
    "dans certains cas, le prompt utilisateur peut ne pas etre la requete la plus pertinente pour identifier le contexte pertinent. Il est donc int√©r√©ssant de g√©n√©rer un document hypoth√©tique qui serait plus perttinent pour identifier le contexte pertinant √† la question de l'utilisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param 1: question embedding, param 2: nombres de vecteur similaires √† r√©cup√©rer\n",
    "D, I = index.search(question_embeddings, k=2) # distance, index\n",
    "retrieved_chunk = [chunks[i] for i in I.tolist()[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "√† noter qu'il existe pleins d'autres strag√©tegie de recherces. search en tant une utilisation simple pour un cas simple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Context information is below.\n",
    "---------------------\n",
    "{retrieved_chunk}\n",
    "---------------------\n",
    "Given the context information and not prior knowledge, answer the query.\n",
    "Query: {question}\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mistral(user_message, model=\"mistral-large-latest\"):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\", \"content\": user_message\n",
    "        }\n",
    "    ]\n",
    "    chat_response = client.chat.complete(\n",
    "        model=model,\n",
    "        messages=messages\n",
    "    )\n",
    "    return (chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Apr√®s son BAC, Yassin a suivi un cursus orient√© √©lectronique et IoT. Il y a fait beaucoup d'√©lectronique et de d√©veloppement en C++ avec Arduino, ainsi que quelques notions en IHM (interface homme-machine) avec des pages HTML, CSS, et JS.\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_mistral(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install notion-client\n",
    "import os\n",
    "from notion_client import Client\n",
    "\n",
    "notion = Client(auth=os.environ[\"NOTION_TOKEN\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Essaie avec langChain\n",
    "maintenant avoir compris les diff√©rentes √©tapes pour mettre en place un RAG, il est temps de passer sur un framework solide pour optimiser tout ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_mistralai.chat_models import ChatMistralAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "# Remplacement des embeddings Mistral par SentenceTransformer\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# loader = TextLoader(\"data.json\")\n",
    "# docs = loader.load()\n",
    "\n",
    "#autre facon de faire en r√©cup√©rrant ma variable my context\n",
    "doc = Document(page_content=my_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split text into chunks \n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    ")\n",
    "documents = text_splitter.split_documents([doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_104022/211966054.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "# D√©finir le mod√®le d'embedding avec SentenceTransformer via HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"all-MiniLM-L6-v2\",  # Vous utilisez d√©j√† ce mod√®le\n",
    "    model_kwargs={'device': 'cuda'},  # Vous pouvez sp√©cifier 'cuda' si vous avez un GPU\n",
    "    encode_kwargs={'normalize_embeddings': True}  # Recommand√© pour la recherche de similarit√©\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the vector store \n",
    "vector = FAISS.from_documents(documents, embeddings)\n",
    "# Define a retriever interface\n",
    "retriever = vector.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "api_key= getpass(\"Type your API Key\")\n",
    "# Define LLM\n",
    "model = ChatMistralAI(mistral_api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prompt template\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yassin a une bonne ma√Ætrise des technologies Java, notamment Spring Boot et Eclipse RCP/SWT pour le d√©veloppement back-end et les interfaces graphiques. Il ma√Ætrise √©galement d'autres technologies pour le d√©veloppement back-end telles que Python, JavaScript, Node.js, Express, et MySQL. Pour le d√©veloppement front-end, il utilise Nuxt.js, Tailwind CSS, Vuetify, et PrimeVue. Il a √©galement des comp√©tences dans l'utilisation d'outils tels que Docker, TensorFlow, Numpy, Git, Jira, Confluence, et Notion, entre autres. Globalement, il a une bonne ma√Ætrise des technologies de d√©veloppement web et back-end.\n"
     ]
    }
   ],
   "source": [
    "# Create a retrieval chain to answer questions\n",
    "document_chain = create_stuff_documents_chain(model, prompt)\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "response = retrieval_chain.invoke({\"input\": \"En francais stp! Quelles technologies maitrise le plus Yassin? \"})\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
